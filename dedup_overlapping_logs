import pandas as pd
from datetime import datetime
from datetime import timedelta

def dedup_overlapping_logs(df: pd.DataFrame, start_date_time: str, end_date_time: str, user: str):
    
    """
    Adjusts log entries in a DataFrame to ensure that there are no overlapping intervals for each user

    Args:
    df (pd.DataFrame): The input DataFrame containing time segments
    start_time (str): The name of the start time field in the DataFrame
    end_time (str): The name of the end time field in the DataFrame
    user (str): The name of the user field in the DataFrame

    Returns:
    pd.DataFrame: A DataFrame with adjusted log entries
    """

    # Ensure the input DataFrame has the required columns
    for col in [start_date_time, end_date_time, user]:
        if col not in df.columns:
            raise ValueError(f"Required column '{col}' not found in DataFrame.")

    # Initialize list to hold all updated rows
    updated_rows = []

    # Group data by user email and process each group individually
    for user, group in df.groupby(user):
        # Create the group and sort each user's data by start time
        group = group.sort_values(by=start_date_time).copy()

        # Initialize variables
        current_end = pd.NaT
        
        # Iterate through each segment of the user's data
        for index, row in group.iterrows():
            try:

                # Initialise start and end time variables
                start = row[start_date_time]
                end = row[end_date_time]
                func_start = start
                func_end = end
                dur = int((end - start).total_seconds())
                func_duration = dur
                func_discard_dur = 0

                if end < start or pd.isnull(end):
                    func_end = start
                    func_discard_dur = dur

                if start >= current_end or pd.isna(current_end):
                    current_end = end
                else:
                    if end <= current_end:
                        func_end = start
                        func_discard_dur = dur
                    else:
                        func_start = current_end
                        func_discard_dur = int((current_end - start).total_seconds())
                    current_end = max(current_end, end)

                func_duration = dur - func_discard_dur

            except Exception as e:
                print(f"Error processing row with index {index}: {e}")
                continue  # Skip to the next iteration on error

            # Create a new dict with the row and additional fields
            updated_row = row.to_dict()
            updated_row['func_start'] = func_start
            updated_row['func_end'] = func_end
            updated_row['func_duration'] = func_duration
            updated_row['func_discard_dur'] = func_discard_dur
            
            # Append the updated row to the list
            updated_rows.append(updated_row)

    result_df = pd.DataFrame(updated_rows)

    return result_df

# Sample usage
data = {
    'string_field': ['ser', 'gre', 'srg', 'pij', 'erg'],
    'user': ['user1', 'user1', 'user2', 'user2', 'user2'],
    'start_time': ['2025-02-02 08:00:00', '2025-02-02 08:30:00', '2025-02-02 09:00:00', '2025-02-02 09:15:00', '2025-02-02 09:20:00'],
    'end_time': ['2025-02-02 08:45:00', '2025-02-02 09:15:00', '2025-02-02 09:30:00', '2025-02-02 09:20:00', '2025-02-02 10:30:00']
    }

df = pd.DataFrame(data)

df['start_time'] = pd.to_datetime(df['start_time'])
df['end_time'] = pd.to_datetime(df['end_time'])

result_df = dedup_overlapping_logs(df, 'start_time', 'end_time', 'user')

result_df
